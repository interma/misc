<?xml version="1.0"?>
<!-- hawq hdfs configuration -->
<configuration>
	<!-- basic -->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/var/data/hadoop/hdfs/nn</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<property>
		<name>fs.checkpoint.dir</name>
		<value>/var/data/hadoop/hdfs/snn</value>
	</property>
	<property>
		<name>fs.checkpoint.edits.dir</name>
		<value>/var/data/hadoop/hdfs/snn</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/var/data/hadoop/hdfs/dn</value>
	</property>
	<property>
		<name>dfs.namenode.http-address</name>
		<value>bds12:50070</value>
	</property>

	<!-- advantage -->
	<property>
		<name>dfs.allow.truncate</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.client.read.shortcircuit</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.domain.socket.path</name>
		<value>/var/data/hadoop/hdfs/dn_socket</value>
	</property>
	<property>
		<name>dfs.block.local-path-access.user</name>
		<value>root</value>
	</property>
	<property>
		<name>dfs.client.socket-timeout</name>
		<value>300000000</value>
	</property>
	<property>
		<name>dfs.client.use.legacy.blockreader.local</name>
		<value>false</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir.perm</name>
		<value>750</value>
	</property>
	<property>
		<name>dfs.datanode.handler.count</name>
		<value>60</value>
	</property>
	<property>
		<name>dfs.datanode.max.transfer.threads</name>
		<value>40960</value>
	</property>
	<property>
		<name>dfs.datanode.socket.write.timeout</name>
		<value>7200000</value>
	</property>
	<property>
		<name>dfs.namenode.accesstime.precision</name>
		<value>0</value>
	</property>
	<property>
		<name>dfs.namenode.handler.count</name>
		<value>600</value>
	</property>
	<property>
		<name>dfs.support.append</name>
		<value>true</value>
	</property>
</configuration>
